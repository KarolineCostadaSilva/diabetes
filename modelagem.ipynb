{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as Bibliotecas Necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modelos\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn_lvq import GlvqModel\n",
    "\n",
    "# Validação e métricas\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "\n",
    "# Bibliotecas adicionais\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/PC/Documents/GitHub/diabetes/mlruns/490920415060799094', creation_time=1732409763939, experiment_id='490920415060799094', last_update_time=1732409763939, lifecycle_stage='active', name='Modelagem de Classificação', tags={}>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configurando o MLflow\n",
    "mlflow.set_experiment(\"Modelagem de Classificação\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os conjuntos de dados\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "validation_data = pd.read_csv('validation_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_bool_to_int(df):\n",
    "#     bool_cols = df.select_dtypes(include=['bool']).columns\n",
    "#     df[bool_cols] = df[bool_cols].astype('int64')\n",
    "#     return df\n",
    "\n",
    "# # Aplicando a conversão nos conjuntos de treinamento e validação\n",
    "# train_data = convert_bool_to_int(train_data)\n",
    "# validation_data = convert_bool_to_int(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando features e target no conjunto de treinamento\n",
    "X_train = train_data.drop('class', axis=1)\n",
    "y_train = train_data['class']\n",
    "\n",
    "# Separando features e target no conjunto de validação\n",
    "X_val = validation_data.drop('class', axis=1)\n",
    "y_val = validation_data['class']\n",
    "\n",
    "# Conjunto de teste\n",
    "X_test = test_data.drop('class', axis=1)\n",
    "y_test = test_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas que estão tipo 'object' em X_test\n",
    "cols_to_convert = ['race', 'gender', 'age', 'weight', 'payer_code', 'medical_specialty', 'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin', 'glyburide.metformin', 'glipizide.metformin', 'glimepiride.pioglitazone', 'metformin.rosiglitazone', 'metformin.pioglitazone', 'change', 'diabetesMed']\n",
    "\n",
    "# Convertendo essas colunas para 'category' em X_test\n",
    "for col in cols_to_convert:\n",
    "    if col in X_test.columns:\n",
    "        X_test[col] = X_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo uma Função de Avaliação\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, model_name):\n",
    "    # Treinando e avaliando o modelo com os dados originais\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_true = y_val\n",
    "    X_val_used = X_val\n",
    "\n",
    "    # Calculando as métricas\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_val_used)\n",
    "        if y_prob.ndim == 1 or y_prob.shape[1] == 2:\n",
    "            y_prob = y_prob[:, -1]  # Para classes binárias\n",
    "            roc_auc = roc_auc_score(y_true, y_prob)\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_true, y_prob, multi_class='ovo', average='weighted')\n",
    "    else:\n",
    "        roc_auc = None\n",
    "    return acc, f1, recall, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os Modelos\n",
    "models = {\n",
    "    'K-NN': KNeighborsClassifier(),\n",
    "    'LVQ': NearestCentroid(),\n",
    "    'Árvore de Decisão': DecisionTreeClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Rede Neural MLP': MLPClassifier(max_iter=500),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': LGBMClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comitê de Redes Neurais Artificiais\n",
    "# Definindo múltiplas redes neurais\n",
    "nn1 = MLPClassifier(hidden_layer_sizes=(50,), activation='relu', solver='adam', max_iter=500, random_state=1)\n",
    "nn2 = MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', solver='sgd', max_iter=500, random_state=2)\n",
    "nn3 = MLPClassifier(hidden_layer_sizes=(50, 50), activation='relu', solver='adam', max_iter=500, random_state=3)\n",
    "\n",
    "# Criando o Comitê\n",
    "committee_nn = VotingClassifier(estimators=[\n",
    "    ('nn1', nn1),\n",
    "    ('nn2', nn2),\n",
    "    ('nn3', nn3)\n",
    "], voting='soft')\n",
    "\n",
    "models['Comitê de Redes Neurais Artificiais'] = committee_nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comitê Heterogêneo (Stacking)\n",
    "# Modelos base\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svm', SVC(random_state=42)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "# Modelo meta\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "# Criando o StackingClassifier\n",
    "stacking_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
    "\n",
    "models['Comitê Heterogêneo (Stacking)'] = stacking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/24 01:28:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN - Acurácia: 0.8749487014129097, F1-Score: 0.8305980818922424, Recall: 0.8749487014129097, ROC AUC: 0.5054859295809839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/24 01:28:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LVQ - Acurácia: 0.5108166735064783, F1-Score: 0.5965374024166652, Recall: 0.5108166735064783, ROC AUC: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/24 01:28:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árvore de Decisão - Acurácia: 0.7972093568622852, F1-Score: 0.8035707856424888, Recall: 0.7972093568622852, ROC AUC: 0.5285752075717296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/24 01:30:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Acurácia: 0.8869672275312188, F1-Score: 0.8338362757298086, Recall: 0.8869672275312188, ROC AUC: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/24 01:31:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Acurácia: 0.8863223310077973, F1-Score: 0.8340782091250809, Recall: 0.8863223310077973, ROC AUC: 0.6411218123035395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/24 01:31:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "c:\\Users\\PC\\.conda\\envs\\venvmodel\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [01:31:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rede Neural MLP - Acurácia: 0.8862050770944481, F1-Score: 0.8350171768105302, Recall: 0.8862050770944481, ROC AUC: 0.6526632715218965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/24 01:31:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Acurácia: 0.8854429266576772, F1-Score: 0.8368679264132897, Recall: 0.8854429266576772, ROC AUC: 0.6455116187509411\n",
      "[LightGBM] [Info] Number of positive: 7714, number of negative: 60513\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1852\n",
      "[LightGBM] [Info] Number of data points in the train set: 68227, number of used features: 83\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113064 -> initscore=-2.059821\n",
      "[LightGBM] [Info] Start training from score -2.059821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/24 01:31:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM - Acurácia: 0.8870258544878935, F1-Score: 0.835878963507557, Recall: 0.8870258544878935, ROC AUC: 0.6652721930265553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/24 01:32:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comitê de Redes Neurais Artificiais - Acurácia: 0.8867327197045202, F1-Score: 0.8345094391946535, Recall: 0.8867327197045202, ROC AUC: 0.6561677114848266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/24 01:42:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comitê Heterogêneo (Stacking) - Acurácia: 0.8864982118778214, F1-Score: 0.8347251165452486, Recall: 0.8864982118778214, ROC AUC: 0.642877957724016\n",
      "                                Modelo  Acurácia  F1-Score    Recall   ROC AUC\n",
      "0                                 K-NN  0.874949  0.830598  0.874949  0.505486\n",
      "1                                  LVQ  0.510817  0.596537  0.510817       NaN\n",
      "2                    Árvore de Decisão  0.797209  0.803571  0.797209  0.528575\n",
      "3                                  SVM  0.886967  0.833836  0.886967       NaN\n",
      "4                        Random Forest  0.886322  0.834078  0.886322  0.641122\n",
      "5                      Rede Neural MLP  0.886205  0.835017  0.886205  0.652663\n",
      "6                              XGBoost  0.885443  0.836868  0.885443  0.645512\n",
      "7                             LightGBM  0.887026  0.835879  0.887026  0.665272\n",
      "8  Comitê de Redes Neurais Artificiais  0.886733  0.834509  0.886733  0.656168\n",
      "9        Comitê Heterogêneo (Stacking)  0.886498  0.834725  0.886498  0.642878\n"
     ]
    }
   ],
   "source": [
    "# Executando os Modelos Básicos e Registrando no MLflow\n",
    "initial_results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        acc, f1, recall, roc_auc = evaluate_model(model, X_train, y_train, X_val, y_val, model_name)\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        if roc_auc is not None:\n",
    "            mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        # Salvar o modelo\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        print(f\"{model_name} - Acurácia: {acc}, F1-Score: {f1}, Recall: {recall}, ROC AUC: {roc_auc}\")\n",
    "        initial_results.append({\n",
    "            'Modelo': model_name,\n",
    "            'Acurácia': acc,\n",
    "            'F1-Score': f1,\n",
    "            'Recall': recall,\n",
    "            'ROC AUC': roc_auc\n",
    "        })\n",
    "\n",
    "# Converte os resultados iniciais em DataFrame\n",
    "initial_results_df = pd.DataFrame(initial_results)\n",
    "\n",
    "# Exibindo os resultados iniciais\n",
    "print(initial_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_9704\\2387988113.py:3: ExperimentalWarning: MLflowCallback is experimental (supported from v1.4.0). The interface can change in the future.\n",
      "  mlflc = MLflowCallback(tracking_uri=mlflow.get_tracking_uri(), metric_name='accuracy')\n"
     ]
    }
   ],
   "source": [
    "# Busca de Hiperparâmetros com Optuna\n",
    "# Configurando o Callback do MLflow para o Optuna\n",
    "mlflc = MLflowCallback(tracking_uri=mlflow.get_tracking_uri(), metric_name='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(model_name, params):\n",
    "    if model_name == 'K-NN':\n",
    "        classifier = KNeighborsClassifier(\n",
    "            n_neighbors=params['n_neighbors'],\n",
    "            weights=params['weights'],\n",
    "            algorithm=params['algorithm']\n",
    "        )\n",
    "    elif model_name == 'LVQ':\n",
    "        classifier = NearestCentroid(\n",
    "            metric=params['metric'],\n",
    "            shrink_threshold=params['shrink_threshold']\n",
    "        )\n",
    "    elif model_name == 'Árvore de Decisão':\n",
    "        classifier = DecisionTreeClassifier(\n",
    "            max_depth=params['max_depth'],\n",
    "            min_samples_split=params['min_samples_split'],\n",
    "            criterion=params['criterion']\n",
    "        )\n",
    "    elif model_name == 'SVM':\n",
    "        classifier = SVC(\n",
    "            C=params['C'],\n",
    "            kernel=params['kernel'],\n",
    "            gamma=params['gamma']\n",
    "        )\n",
    "    elif model_name == 'Random Forest':\n",
    "        classifier = RandomForestClassifier(\n",
    "            n_estimators=params['n_estimators'],\n",
    "            max_depth=params['max_depth'],\n",
    "            min_samples_split=params['min_samples_split']\n",
    "        )\n",
    "    elif model_name == 'Rede Neural MLP':\n",
    "        classifier = MLPClassifier(\n",
    "            hidden_layer_sizes=params['hidden_layer_sizes'],\n",
    "            activation=params['activation'],\n",
    "            solver=params['solver'],\n",
    "            alpha=params['alpha'],\n",
    "            max_iter=500\n",
    "        )\n",
    "    elif model_name == 'Comitê de Redes Neurais Artificiais':\n",
    "        nn1 = MLPClassifier(\n",
    "            hidden_layer_sizes=params['hidden_layer_sizes'],\n",
    "            activation=params['activation'],\n",
    "            solver=params['solver'],\n",
    "            max_iter=500,\n",
    "            random_state=1\n",
    "        )\n",
    "        nn2 = MLPClassifier(\n",
    "            hidden_layer_sizes=params['hidden_layer_sizes'],\n",
    "            activation=params['activation'],\n",
    "            solver=params['solver'],\n",
    "            max_iter=500,\n",
    "            random_state=2\n",
    "        )\n",
    "        nn3 = MLPClassifier(\n",
    "            hidden_layer_sizes=params['hidden_layer_sizes'],\n",
    "            activation=params['activation'],\n",
    "            solver=params['solver'],\n",
    "            max_iter=500,\n",
    "            random_state=3\n",
    "        )\n",
    "        classifier = VotingClassifier(\n",
    "            estimators=[\n",
    "                ('nn1', nn1),\n",
    "                ('nn2', nn2),\n",
    "                ('nn3', nn3)\n",
    "            ],\n",
    "            voting='soft'\n",
    "        )\n",
    "    elif model_name == 'Comitê Heterogêneo (Stacking)':\n",
    "        final_estimator = LogisticRegression(\n",
    "            C=params['C'],\n",
    "            penalty=params['penalty'],\n",
    "            solver=params['solver']\n",
    "        )\n",
    "        estimators = [\n",
    "            ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "            ('svm', SVC(random_state=42)),\n",
    "            ('knn', KNeighborsClassifier())\n",
    "        ]\n",
    "        classifier = StackingClassifier(\n",
    "            estimators=estimators,\n",
    "            final_estimator=final_estimator,\n",
    "            cv=5\n",
    "        )\n",
    "    elif model_name == 'XGBoost':\n",
    "        classifier = XGBClassifier(\n",
    "            n_estimators=params['n_estimators'],\n",
    "            max_depth=params['max_depth'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            subsample=params['subsample'],\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss'\n",
    "        )\n",
    "    elif model_name == 'LightGBM':\n",
    "        classifier = LGBMClassifier(\n",
    "            n_estimators=params['n_estimators'],\n",
    "            num_leaves=params['num_leaves'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            subsample=params['subsample']\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Modelo {model_name} não reconhecido.\")\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_factory(model_name):\n",
    "    def objective(trial):\n",
    "        params = {}\n",
    "        # Definir os hiperparâmetros para cada modelo\n",
    "        if model_name == 'K-NN':\n",
    "            params['n_neighbors'] = trial.suggest_int('n_neighbors', 1, 30)\n",
    "            params['weights'] = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "            params['algorithm'] = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "        \n",
    "        elif model_name == 'LVQ':\n",
    "            params['metric'] = trial.suggest_categorical('metric', ['euclidean', 'manhattan'])\n",
    "            use_shrinkage = trial.suggest_categorical('use_shrinkage', [True, False])\n",
    "            params['shrink_threshold'] = trial.suggest_float('shrink_threshold', 0.0, 1.0) if use_shrinkage else None\n",
    "        \n",
    "        elif model_name == 'Árvore de Decisão':\n",
    "            params['max_depth'] = trial.suggest_int('max_depth', 1, 20)\n",
    "            params['min_samples_split'] = trial.suggest_int('min_samples_split', 2, 10)\n",
    "            params['criterion'] = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "        \n",
    "        elif model_name == 'SVM':\n",
    "            params['C'] = trial.suggest_float('C', 0.1, 10.0, log=True)\n",
    "            params['kernel'] = trial.suggest_categorical('kernel', ['linear', 'rbf'])\n",
    "            params['gamma'] = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "        \n",
    "        elif model_name == 'Random Forest':\n",
    "            params['n_estimators'] = trial.suggest_int('n_estimators', 50, 300)\n",
    "            params['max_depth'] = trial.suggest_int('max_depth', 2, 20)\n",
    "            params['min_samples_split'] = trial.suggest_int('min_samples_split', 2, 10)\n",
    "        \n",
    "        elif model_name == 'Rede Neural MLP':\n",
    "            params['hidden_layer_sizes'] = trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50,50)])\n",
    "            params['activation'] = trial.suggest_categorical('activation', ['tanh', 'relu'])\n",
    "            params['solver'] = trial.suggest_categorical('solver', ['sgd', 'adam'])\n",
    "            params['alpha'] = trial.suggest_float('alpha', 1e-5, 1e-1, log=True)\n",
    "        \n",
    "        elif model_name == 'Comitê de Redes Neurais Artificiais':\n",
    "            params['hidden_layer_sizes'] = trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50,50)])\n",
    "            params['activation'] = trial.suggest_categorical('activation', ['tanh', 'relu'])\n",
    "            params['solver'] = trial.suggest_categorical('solver', ['sgd', 'adam'])\n",
    "        \n",
    "        elif model_name == 'Comitê Heterogêneo (Stacking)':\n",
    "            params['C'] = trial.suggest_float('C', 0.1, 10.0, log=True)\n",
    "            params['penalty'] = trial.suggest_categorical('penalty', ['l2'])\n",
    "            params['solver'] = trial.suggest_categorical('solver', ['lbfgs'])\n",
    "        \n",
    "        elif model_name == 'XGBoost':\n",
    "            params['n_estimators'] = trial.suggest_int('n_estimators', 50, 300)\n",
    "            params['max_depth'] = trial.suggest_int('max_depth', 3, 15)\n",
    "            params['learning_rate'] = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "            params['subsample'] = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "        \n",
    "        elif model_name == 'LightGBM':\n",
    "            params['n_estimators'] = trial.suggest_int('n_estimators', 50, 300)\n",
    "            params['num_leaves'] = trial.suggest_int('num_leaves', 31, 150)\n",
    "            params['learning_rate'] = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "            params['subsample'] = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Modelo {model_name} não reconhecido.\")\n",
    "        \n",
    "        classifier = build_classifier(model_name, params)\n",
    "        \n",
    "        acc = cross_val_score(classifier, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "        return acc\n",
    "    return objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executando as Otimizações com Optuna\n",
    "n_trials = 5  # Número de iterações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para armazenar os melhores modelos e seus scores\n",
    "best_models = {}\n",
    "best_params = {}\n",
    "cv_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 01:42:11,191] A new study created in memory with name: Modelagem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otimização para o modelo: K-NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 01:42:18,874] Trial 0 finished with value: 0.8869362571910037 and parameters: {'n_neighbors': 21, 'weights': 'uniform', 'algorithm': 'brute'}. Best is trial 0 with value: 0.8869362571910037.\n",
      "[I 2024-11-24 01:43:14,945] Trial 1 finished with value: 0.8869362571910037 and parameters: {'n_neighbors': 21, 'weights': 'uniform', 'algorithm': 'ball_tree'}. Best is trial 0 with value: 0.8869362571910037.\n",
      "[I 2024-11-24 01:43:22,448] Trial 2 finished with value: 0.8867750356378183 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'algorithm': 'brute'}. Best is trial 0 with value: 0.8869362571910037.\n",
      "[I 2024-11-24 01:43:29,664] Trial 3 finished with value: 0.8869362571910037 and parameters: {'n_neighbors': 26, 'weights': 'uniform', 'algorithm': 'auto'}. Best is trial 0 with value: 0.8869362571910037.\n",
      "[I 2024-11-24 01:43:39,327] Trial 4 finished with value: 0.8856171356265025 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree'}. Best is trial 0 with value: 0.8869362571910037.\n",
      "[I 2024-11-24 01:43:45,614] A new study created in memory with name: Modelagem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otimização para o modelo: LVQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 01:43:45,917] Trial 0 finished with value: 0.5102085562235421 and parameters: {'metric': 'euclidean', 'use_shrinkage': False}. Best is trial 0 with value: 0.5102085562235421.\n",
      "[I 2024-11-24 01:43:46,415] Trial 1 finished with value: 0.5095783059121426 and parameters: {'metric': 'euclidean', 'use_shrinkage': True, 'shrink_threshold': 0.48093190148436094}. Best is trial 0 with value: 0.5102085562235421.\n",
      "[I 2024-11-24 01:43:46,900] Trial 2 finished with value: 0.5101059577602903 and parameters: {'metric': 'euclidean', 'use_shrinkage': True, 'shrink_threshold': 0.05967789660956835}. Best is trial 0 with value: 0.5102085562235421.\n",
      "[I 2024-11-24 01:43:47,446] Trial 3 finished with value: 0.5331026784311701 and parameters: {'metric': 'manhattan', 'use_shrinkage': True, 'shrink_threshold': 0.5315513738418384}. Best is trial 3 with value: 0.5331026784311701.\n",
      "[I 2024-11-24 01:43:48,005] Trial 4 finished with value: 0.5327948798190674 and parameters: {'metric': 'manhattan', 'use_shrinkage': True, 'shrink_threshold': 0.6110235106775829}. Best is trial 3 with value: 0.5331026784311701.\n",
      "[I 2024-11-24 01:43:48,807] A new study created in memory with name: Modelagem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otimização para o modelo: Árvore de Decisão\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 01:43:49,646] Trial 0 finished with value: 0.8718688846226204 and parameters: {'max_depth': 14, 'min_samples_split': 4, 'criterion': 'entropy'}. Best is trial 0 with value: 0.8718688846226204.\n",
      "[I 2024-11-24 01:43:50,598] Trial 1 finished with value: 0.8683512199565122 and parameters: {'max_depth': 15, 'min_samples_split': 5, 'criterion': 'gini'}. Best is trial 0 with value: 0.8718688846226204.\n",
      "[I 2024-11-24 01:43:51,375] Trial 2 finished with value: 0.8813959391012883 and parameters: {'max_depth': 10, 'min_samples_split': 5, 'criterion': 'entropy'}. Best is trial 2 with value: 0.8813959391012883.\n",
      "[I 2024-11-24 01:43:52,098] Trial 3 finished with value: 0.8827297201976781 and parameters: {'max_depth': 9, 'min_samples_split': 2, 'criterion': 'entropy'}. Best is trial 3 with value: 0.8827297201976781.\n",
      "[I 2024-11-24 01:43:52,577] Trial 4 finished with value: 0.8868189938252844 and parameters: {'max_depth': 4, 'min_samples_split': 3, 'criterion': 'entropy'}. Best is trial 4 with value: 0.8868189938252844.\n",
      "[I 2024-11-24 01:43:53,549] A new study created in memory with name: Modelagem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otimização para o modelo: SVM\n"
     ]
    }
   ],
   "source": [
    "for model_name in models.keys():\n",
    "    print(f\"Otimização para o modelo: {model_name}\")\n",
    "    study = optuna.create_study(direction='maximize', study_name='Modelagem', sampler=optuna.samplers.TPESampler(seed=123))\n",
    "    study.optimize(objective_factory(model_name), n_trials=n_trials, callbacks=[mlflc])\n",
    "    \n",
    "    # Armazenando os melhores hiperparâmetros\n",
    "    best_params[model_name] = study.best_params\n",
    "    \n",
    "    # Criando o classificador com os melhores hiperparâmetros\n",
    "    classifier = build_classifier(model_name, best_params[model_name])\n",
    "    \n",
    "    # Armazenando o classificador\n",
    "    best_models[model_name] = classifier\n",
    "    \n",
    "    # Armazenando os scores dos folds\n",
    "    acc_scores = cross_val_score(classifier, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_results[model_name] = acc_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação dos Melhores Modelos e Registro no MLflow\n",
    "results = []\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    with mlflow.start_run(run_name=f\"{model_name} - Optuna HPO\"):\n",
    "        acc, f1, recall, roc_auc = evaluate_model(model, X_train, y_train, X_val, y_val)\n",
    "        mlflow.log_params(best_params[model_name])\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        if roc_auc is not None:\n",
    "            mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        # Salvar o modelo\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        print(f\"{model_name} com Optuna HPO - Acurácia: {acc}, F1-Score: {f1}, Recall: {recall}, ROC AUC: {roc_auc}\")\n",
    "        results.append({\n",
    "            'Modelo': model_name,\n",
    "            'Acurácia': acc,\n",
    "            'F1-Score': f1,\n",
    "            'Recall': recall,\n",
    "            'ROC AUC': roc_auc\n",
    "        })\n",
    "\n",
    "# Converte os resultados em DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando o Melhor Modelo automaticamente com base na Acurácia\n",
    "best_model_name = results_df.loc[results_df['Acurácia'].idxmax(), 'Modelo']\n",
    "best_model = best_models[best_model_name]\n",
    "print(f\"O melhor modelo é: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o Melhor Modelo no Conjunto Combinado e Avaliando no Conjunto de Teste\n",
    "# Combinando os conjuntos de treinamento e validação\n",
    "X_combined = pd.concat([X_train, X_val])\n",
    "y_combined = np.concatenate([y_train, y_val])\n",
    "\n",
    "# Treinando o melhor modelo\n",
    "best_model.fit(X_combined, y_combined)\n",
    "\n",
    "# Avaliando no conjunto de teste\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "acc_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "if hasattr(best_model, \"predict_proba\"):\n",
    "    y_prob_test = best_model.predict_proba(X_test)\n",
    "    if y_prob_test.ndim == 1 or y_prob_test.shape[1] == 2:\n",
    "        y_prob_test = y_prob_test[:, -1]  # Para classes binárias\n",
    "        roc_auc_test = roc_auc_score(y_test, y_prob_test)\n",
    "    else:\n",
    "        roc_auc_test = roc_auc_score(y_test, y_prob_test, multi_class='ovo', average='weighted')\n",
    "else:\n",
    "    roc_auc_test = None\n",
    "\n",
    "print(f\"Desempenho no conjunto de teste - Acurácia: {acc_test}, F1-Score: {f1_test}, Recall: {recall_test}, ROC AUC: {roc_auc_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registrando no MLflow\n",
    "with mlflow.start_run(run_name=\"Melhor Modelo - Teste\"):\n",
    "    mlflow.log_param(\"model_type\", best_model_name)\n",
    "    mlflow.log_metric(\"accuracy_test\", acc_test)\n",
    "    mlflow.log_metric(\"f1_score_test\", f1_test)\n",
    "    mlflow.log_metric(\"recall_test\", recall_test)\n",
    "    if roc_auc_test is not None:\n",
    "        mlflow.log_metric(\"roc_auc_test\", roc_auc_test)\n",
    "    mlflow.sklearn.log_model(best_model, \"Melhor_Modelo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizações Adicionais\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Matriz de Confusão\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Matriz de Confusão - Conjunto de Teste\")\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "if roc_auc_test is not None and len(np.unique(y_test)) == 2:\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob_test)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc_test:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Linha diagonal\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Curva ROC - Conjunto de Teste')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "elif roc_auc_test is not None:\n",
    "    print(\"Curva ROC para problemas multiclasse não está implementada neste código.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação dos Modelos\n",
    "# Já temos o DataFrame results_df com as métricas dos modelos\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando as métricas\n",
    "results_df_melted = results_df.melt(id_vars='Modelo', value_vars=['Acurácia', 'F1-Score', 'Recall', 'ROC AUC'], var_name='Métrica', value_name='Valor')\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x='Modelo', y='Valor', hue='Métrica', data=results_df_melted)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Comparação das Métricas dos Modelos')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementação da Metodologia de Janez Demsar\n",
    "from scipy.stats import friedmanchisquare\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Usando os scores de cross-validation armazenados em cv_results\n",
    "scores_df = pd.DataFrame(cv_results)\n",
    "\n",
    "# Teste de Friedman\n",
    "stat, p = friedmanchisquare(*[scores_df[model] for model in scores_df.columns])\n",
    "print(f'Estatística: {stat}, p-valor: {p}')\n",
    "\n",
    "# Se p-valor < 0.05, há diferença significativa\n",
    "if p < 0.05:\n",
    "    print('Diferença significativa entre os modelos. Realizando teste de Nemenyi.')\n",
    "    nemenyi = sp.posthoc_nemenyi_friedman(scores_df)\n",
    "    print(nemenyi)\n",
    "else:\n",
    "    print('Não há diferença significativa entre os modelos.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
