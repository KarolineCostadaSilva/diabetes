{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pós-Graduação Strictu Sensu em Ciências da Computação\n",
    "----\n",
    "**Universidade Federal de Pernambuco**\n",
    "\n",
    "\n",
    "**Disciplina**: Aprendizado de Máquina\n",
    "\n",
    "**Discentes**: Jose Adeljan Marinho da Silva\n",
    "\n",
    "Matheus Hopper Jansen Costa\n",
    "\n",
    "Heitor Leite Ramos\n",
    "\n",
    "Jefferson Medeiros Norberto\n",
    "\n",
    "Karoline Juliana Costa da Silva\n",
    "\n",
    "\n",
    "**Docentes**: Leandro Maciel Almeida\n",
    "\n",
    "Francisco de Assis Tenorio de Carvalho\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sumário:\n",
    "\n",
    "0. [Importação das bibliotecas](#importação-das-bibliotecas-utilizadas)\n",
    "1. [Introdução](#introdução)\n",
    "2. [Análise Exploratória dos Dados](#análise-exploratória-dos-dados)\n",
    "3. [Preparação dos dados](#preparação-dos-dados)\n",
    "4. [Modelagem e Otimização](#modelagem-e-otimização)\n",
    "5. [Avaliação dos Modelos](#avaliação-dos-modelos)\n",
    "6. [Análise de Custo-Benefício](#análise-de-custo-benefício)\n",
    "7. [Teste de Estresse dos Modelos](#teste-de-estresse-dos-modelos)\n",
    "8. [Discussão sobre Limitações e Futuras Melhorias](#discussão-sobre-limitações-e-futuras-melhorias)\n",
    "9. [Conclusão](#conclusão)\n",
    "10. [Referências](#referências)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação das bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openml in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (0.15.0)\n",
      "Requirement already satisfied: liac-arff>=2.4.0 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from openml) (2.5.0)\n",
      "Requirement already satisfied: xmltodict in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from openml) (0.14.2)\n",
      "Requirement already satisfied: requests in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from openml) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from openml) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from openml) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from openml) (2.2.3)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from openml) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.6.2 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from openml) (2.1.3)\n",
      "Requirement already satisfied: minio in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from openml) (7.2.12)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from openml) (18.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from openml) (4.67.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from openml) (24.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from pandas>=1.0.0->openml) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from pandas>=1.0.0->openml) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from python-dateutil->openml) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from scikit-learn>=0.18->openml) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from scikit-learn>=0.18->openml) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from minio->openml) (2024.8.30)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from minio->openml) (2.2.3)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from minio->openml) (23.1.0)\n",
      "Requirement already satisfied: pycryptodome in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from minio->openml) (3.21.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from minio->openml) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from requests->openml) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from requests->openml) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from tqdm->openml) (0.4.6)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from argon2-cffi->minio->openml) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\pc\\.conda\\envs\\venvmodel\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\.conda\\envs\\venvmodel\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Modelos\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Validação e métricas\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import friedmanchisquare\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Bibliotecas adicionais\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import time\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O diabetes mellitus é considerado uma epidemia global, representando um desafio significativo para os sistemas de saúde. Dados da Organização Mundial da Saúde indicam que, em 2014, mais de 422 milhões de pessoas viviam com diabetes, e em 2016, 1,6 milhão de mortes foram atribuídas diretamente à doença (World Health Organization (WHO) (2020)). No Brasil, o cenário também é preocupante: a Pesquisa Nacional de Saúde de 2019 reportou uma prevalência de 7,7% entre adultos acima de 18 anos (PNS (2019)), o que equivale a cerca de 12,3 milhões de pessoas. Este impacto, tanto clínico quanto social, reforça a necessidade de estratégias baseadas em dados para otimizar o cuidado e reduzir os custos associados ao manejo do diabetes.\n",
    "\n",
    "O presente estudo utiliza o dataset \"Diabetes130US\", que reúne informações clínicas e hospitalares de pacientes diabéticos atendidos em 130 hospitais nos Estados Unidos ao longo de uma década (1999–2008). Com mais de 40 atributos, o conjunto de dados possibilita a análise de fatores clínicos, demográficos e resultados hospitalares, oferecendo insights valiosos para a identificação de padrões de tratamento e fatores que impactam a saúde dos pacientes.\n",
    "\n",
    "Entre os desafios investigados, destaca-se a previsão de readmissões hospitalares. A antecipação de quais pacientes têm maior probabilidade de serem readmitidos pode auxiliar na implementação de intervenções preventivas, na melhoria da qualidade do atendimento e na redução de custos com hospitalizações desnecessárias. Esse objetivo requer a aplicação de técnicas de aprendizado de máquina, que permitem transformar dados brutos em informações acionáveis.\n",
    "\n",
    "O projeto seguiu uma abordagem iterativa e cíclica, alinhada ao ciclo de vida de projetos de ciência de dados. Iniciou-se com o entendimento do problema e dos dados, etapa crucial para garantir que as análises estejam direcionadas às questões centrais do estudo (Fawcett and Provost (2013), Jiawei Han and Pei (2012)). O dataset foi minuciosamente explorado para compreender seus atributos, identificar lacunas, eliminar redundâncias e realizar transformações necessárias. Esse cuidado na preparação garantiu maior qualidade para a modelagem e reduziu riscos de interpretações equivocadas.\n",
    "\n",
    "Com foco na previsão de readmissões, o relatório documenta o processo de seleção, treinamento e avaliação de diferentes algoritmos de aprendizado de máquina. Modelos como K-Nearest Neighbors (K-NN), Support Vector Machine (SVM), Random Forest, XGBoost, entre outros, foram otimizados e comparados usando validação cruzada estratificada, técnicas de balanceamento de dados e análise estatística. O trabalho destaca a flexibilidade da pipeline implementada, que permitiu revisitar etapas anteriores sempre que necessário, promovendo melhorias contínuas na qualidade e precisão das predições.\n",
    "\n",
    "Assim, este estudo não apenas contribui para a compreensão dos fatores que influenciam as readmissões hospitalares em pacientes diabéticos, mas também propõe soluções práticas para apoiar decisões clínicas, reduzir custos e aprimorar o atendimento em saúde pública."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendimento do negócio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No contexto do diabetes mellitus, compreender os fatores que impactam diretamente a saúde dos pacientes e a eficiência do sistema de saúde é fundamental para enfrentar os desafios associados ao manejo da doença. As principais questões de negócio identificadas neste projeto abordam aspectos críticos relacionados a complicações, intervenções preventivas e otimização de recursos. Abaixo segue os questionamentos realizados durante o estudo.\n",
    "\n",
    "### Quais fatores demográficos e clínicos influenciam significativamente a readmissão hospitalar de pacientes diabéticos?\n",
    "Readmissões hospitalares representam um indicador importante da qualidade do atendimento médico e possuem um impacto financeiro significativo. Pacientes diabéticos frequentemente retornam ao hospital devido a complicações como hiperglicemia, hipoglicemia ou condições associadas como hipertensão e insuficiência renal. Identificar fatores que aumentam o risco de readmissão pode orientar intervenções personalizadas e prevenir hospitalizações desnecessárias, melhorando a qualidade de vida do paciente e reduzindo custos. Fatores que podem contruibuir com esse tipo de questionamento são: Idade avançada, duração do diabetes, número de comorbidades, tipo de medicação utilizada e nível de controle glicêmico.\n",
    "\n",
    "### Como os diferentes regimes de medicação afetam os resultados dos pacientes?\n",
    "O tratamento do diabetes inclui uma combinação de medicamentos antidiabéticos orais, insulina e mudanças no estilo de vida. A escolha inadequada do regime pode levar a complicações ou efeitos colaterais. Entender como diferentes combinações de medicamentos afetam a progressão da doença e os desfechos clínicos permite personalizar os tratamentos e reduzir efeitos adversos. Avaliar se pacientes tratados com insulina têm maior probabilidade de complicações ou readmissões em comparação com aqueles que utilizam antidiabéticos orais.\n",
    "\n",
    "### Existem padrões nos resultados laboratoriais que podem prever complicações?\n",
    "Dados laboratoriais, como níveis de hemoglobina glicada (HbA1c), glicemia em jejum, função renal e lipidograma, fornecem indicadores críticos do estado de saúde dos pacientes. Identificar padrões nestes dados pode permitir a detecção precoce de complicações, como insuficiência renal ou doenças cardiovasculares, possibilitando intervenções antes que problemas graves ocorram. Desenvolver alertas automatizados para identificar pacientes com maior risco de desenvolver complicações com base em seus resultados laboratoriais.\n",
    "\n",
    "### Qual é o impacto do tempo de internação nos desfechos clínicos?\n",
    "O tempo de internação é um fator que afeta diretamente os custos hospitalares e pode estar relacionado à gravidade da condição do paciente. Internações mais longas podem ser indicativas de complicações ou de cuidados inadequados. Determinar o impacto do tempo de internação pode ajudar a equilibrar eficiência operacional e qualidade do atendimento, ajustando protocolos para atender melhor os pacientes enquanto minimiza custos. Avaliar se internações mais longas resultam em maior taxa de readmissão, sugerindo necessidade de revisão nos cuidados pós-alta.\n",
    "\n",
    "## Fonte dos dados\n",
    "Dados clínicos de 101.766 internações relacionadas ao diabetes em 130 hospitais dos EUA entre 1999 e 2008, sendo dados estruturados com 48 atributos, incluindo numéricos e nominais, cobrindo informações demográficos: raça, gênero, idade, informações Clínicas: diagnósticos, resultados de testes laboratoriais, medicamentos administrados, tipo de admissão, tempo no hospital, fonte deadmissão.\n",
    "\n",
    "### Qualidade e Integridade dos Dados\n",
    " • Valores Ausentes: 192.849 valores ausentes, afetando 98,97% das instâncias.\n",
    "\n",
    " • Atributos com Altos Níveis de Ausência:– weight: 98.569 valores ausentes.– medical_specialty: 49.949 valores ausentes.\n",
    "\n",
    " • Desbalanceamento de Classes: Classe majoritária representa 53,91% dos dados.\n",
    "\n",
    "### Limitações dos Dados Existentes\n",
    " • Elevado número de valores ausentes em atributos críticos pode comprometer análises.\n",
    "\n",
    " • Desbalanceamento de classes pode afetar a eficácia de modelos preditivos.\n",
    "\n",
    " • Limitação geográfica: Dados restritos aos EUA, podendo limitar generalizações\n",
    "\n",
    "## Restrições\n",
    " • Tempo: Prazo limitado para conclusão do projeto.\n",
    " \n",
    " • Recursos: Recursos computacionais limitados para processamento e modelagem.\n",
    " \n",
    " • Dados: Qualidade dos dados afetada por valores ausentes e possíveis inconsistências.\n",
    "\n",
    "## Assunções\n",
    " • Os dados são representativos da população de pacientes diabéticos internados nos EUA no período.\n",
    " \n",
    " • As práticas clínicas não sofreram mudanças drásticas que invalidem comparações temporais.\n",
    " \n",
    " • As codificações de diagnósticos e procedimentos são consistentes em todo o dataset.\n",
    "\n",
    "O presente projeto visa explorar essas questões utilizando o dataset \"Diabetes130US\", que contém informações de 101.766 internações hospitalares nos Estados Unidos, cobrindo dez anos de atendimento (1999–2008). Com 48 atributos clínicos e demográficos, o dataset oferece um panorama detalhado sobre diagnósticos, tratamentos e desfechos de pacientes diabéticos internados. A análise desse conjunto de dados tem como objetivo identificar fatores-chave que impactam os resultados clínicos e otimizar protocolos de tratamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendimento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta Inicial de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset **Diabetes130US**, utilizado neste projeto, foi obtido por meio da plataforma OpenML, uma fonte confiável para pesquisa em ciência de dados. Este conjunto de dados contém mais de 100.000 registros clínicos coletados de pacientes diabéticos internados em 130 hospitais e redes de serviços integrados nos Estados Unidos, abrangendo o período de dez anos, de 1999 a 2008. Cada registro representa uma internação hospitalar, contendo informações detalhadas sobre características clínicas, demográficas e resultados clínicos dos pacientes.\n",
    "\n",
    "A coleta foi realizada utilizando a API do OpenML com a linguagem Python. O dataset foi acessado por meio de seu ID único (45069) e carregado no ambiente de análise com a função `get_dataset()` da biblioteca OpenML. Após o download, o arquivo foi salvo no formato CSV e posteriormente convertido para um DataFrame da biblioteca Pandas, permitindo uma manipulação mais eficiente dos dados durante a análise.\n",
    "\n",
    "O dataset possui 48 atributos, incluindo informações como diagnósticos principais, especialidade médica, faixa de peso, faixa de idade e o ID do paciente. O formato tabular dos dados facilita o processamento, enquanto os valores foram ajustados para melhorar a exibição e interpretação. Um exemplo dos cinco primeiros registros dos quatro primeiros atributos foi apresentado na Tabela 1, demonstrando variáveis como tipo de admissão, tipo de alta, tempo de internação e número de procedimentos laboratoriais realizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrição dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados representa 10 anos (1999-2008) de atendimento clínico em 130 hospitais dos EUA e redes de entrega integradas. Ele inclui mais de 50 características que representam os resultados dos pacientes e dos hospitais. As informações foram extraídas do banco de dados para atendimentos que satisfizeram os seguintes critérios:\n",
    "\n",
    "• É um atendimento de internação (uma admissão hospitalar).\n",
    "\n",
    "• É um atendimento diabético, ou seja, um durante o qual qualquer tipo de diabetes foi registrado no sistema como diagnóstico.\n",
    "\n",
    "• A duração da estadia foi de pelo menos 1 dia e no máximo 14 dias.\n",
    "\n",
    "• Exames laboratoriais foram realizados durante o atendimento.\n",
    "\n",
    "• Medicamentos foram administrados durante o atendimento.\n",
    "\n",
    "Os dados contêm atributos como número do paciente, raça, gênero, idade, tipo de admissão, tempo no hospital, especialidade médica do médico responsável, número de testes laboratoriais realizados, resultado do teste de HbA1c, diagnóstico, número de medicamentos, medicamentos para diabetes, número de consultas ambulatoriais, internações e visitas de emergência no ano anterior à hospitalização, entre outros, totalizando 48 atributos no conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicionário de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• race: Valores possíveis: Caucasian, Asian, African American, Hispanic e Other.\n",
    "\n",
    "• gender: Valores possíveis: Male, Female e Unknown/Invalid.\n",
    "\n",
    "• age: Agrupados em intervalos de 10 anos: (0, 10), (10, 20), ..., (90, 100).\n",
    "\n",
    "• weight: Peso em libras.\n",
    "\n",
    "• admission_type_id: Identificador inteiro correspondente a 9 tipos distintos de admissão (ex: emergência, urgência, eletiva, recém-nascido e não disponível).\n",
    "\n",
    "• discharge_disposition_id: Identificador inteiro correspondente a 29 valores distintos (ex: enviado para casa, expirou, não disponível).\n",
    "\n",
    "• admission_source_id: Identificador inteiro correspondente a 21 valores distintos (ex: encaminhamento médico, transferência de hospital).\n",
    "\n",
    "• time_in_hospital: Número inteiro de dias entre a admissão e a alta.\n",
    "\n",
    "• payer_code: Identificador inteiro correspondente a 23 valores distintos (ex: BlueCross/Blue Shield, Medicare, auto-pagamento).\n",
    "\n",
    "• medical_specialty: Identificador inteiro de uma especialidade médica correspondente a 84 valores distintos (ex: cardiologia, medicina interna, clínica geral, cirurgia).\n",
    "\n",
    "• num_lab_procedures: Número de testes de laboratório realizados durante a consulta.\n",
    "\n",
    "• num_procedures: Número de procedimentos (exceto testes de laboratório) realizados durante a consulta.\n",
    "\n",
    "• num_medications: Número de medicamentos genéricos distintos administrados durante a consulta.\n",
    "\n",
    "• number_outpatient: Número de consultas ambulatoriais do paciente no ano anterior à consulta.\n",
    "\n",
    "• number_emergency: Número de visitas de emergência do paciente no ano anterior à consulta.\n",
    "\n",
    "• number_inpatient: Número de visitas hospitalares do paciente no ano anterior à consulta.\n",
    "\n",
    "• diag_1: Diagnóstico primário (codificado como os três primeiros dígitos da CID-9); 848 valores distintos.\n",
    "\n",
    "• diag_2: Diagnóstico secundário (codificado como os três primeiros dígitos da CID-9); 923 valores distintos.\n",
    "\n",
    "• diag_3: Diagnóstico secundário adicional (codificado como os três primeiros dígitos da CID-9); 954 valores distintos.\n",
    "\n",
    "• number_diagnoses: Número de diagnósticos inseridos no sistema.\n",
    "\n",
    "• max_glu_serum: Teste sérico de glicose que indica a faixa do resultado ou se o teste não foi realizado. Valores: > 200, > 300, normal e nenhum (se não medido).\n",
    "\n",
    "• A1Cresult: Teste A1C que indica o intervalo do resultado ou se o teste não foi realizado. Valores: > 8 (se o resultado for maior que 8%), > 7 (maior que 7% e menor que 8%), normal (se o resultado for inferior a 7%) e nenhum (se não medido)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodologia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = openml.datasets.get_dataset(45069)\n",
    "\n",
    "# Carregar o dataset\n",
    "X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "# Mostrar as primeiras linhas do DataFrame\n",
    "df = pd.concat([X, y], axis=1)\n",
    "df_bruto = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação do target em binário\n",
    "df['class'] = [1 if each=='<30' else 0 for each in df['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação das colunas categóricas em string\n",
    "categorical_cols = df.select_dtypes(include='category').columns\n",
    "df[categorical_cols] = df[categorical_cols].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"race\"].fillna(df[\"race\"].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.loc[~df.discharge_disposition_id.isin([11,18,19,20,21,7,25,26])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_list = ['diag_1','diag_2','diag_3']\n",
    "\n",
    "for col in diag_list:\n",
    "    df[col].fillna('NaN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformFunc(value):\n",
    "    value = re.sub(\"V[0-9]*\", \"0\", value) # V\n",
    "    value = re.sub(\"E[0-9]*\", \"0\", value) # E\n",
    "    value = re.sub('NaN', \"-1\", value) # Nan\n",
    "    return value\n",
    "\n",
    "def transformCategory(value):\n",
    "    if value>=390 and value<=459 or value==785:\n",
    "        category = 'Circulatory'\n",
    "    elif value>=460 and value<=519 or value==786:\n",
    "        category = 'Respiratory'\n",
    "    elif value>=520 and value<=579 or value==787:\n",
    "        category = 'Digestive'\n",
    "    elif value==250:\n",
    "        category = 'Diabetes'\n",
    "    elif value>=800 and value<=999:\n",
    "        category = 'Injury'\n",
    "    elif value>=710 and value<=739:\n",
    "        category = 'Musculoskeletal'\n",
    "    elif value>=580 and value<=629 or value==788:\n",
    "        category = 'Genitourinary'\n",
    "    elif value>=140 and value<=239 :\n",
    "        category = 'Neoplasms'\n",
    "    elif value==-1:\n",
    "        category = 'NAN'\n",
    "    else :\n",
    "        category = 'Other'\n",
    "\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in diag_list:\n",
    "    df[col] = df[col].apply(transformFunc)\n",
    "    df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in diag_list:\n",
    "    df[col] = df[col].apply(transformCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=['uint8', 'int64']).columns.tolist()\n",
    "numerical_columns.remove('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LocalOutlierFactor(n_neighbors = 2 , contamination = 0.1)\n",
    "clf.fit_predict(df[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.11237244e+00, -1.00000000e+00, -1.05618622e+00, -1.00000000e+00,\n",
       "       -9.64101615e-01, -9.76153125e-01, -1.20628580e+00, -1.00000000e+00,\n",
       "       -9.54124145e-01, -1.00000000e+00, -1.35838165e+00, -1.06769362e+00,\n",
       "       -9.73606798e-01, -9.65428645e-01, -1.18383741e+00, -1.16313671e+00,\n",
       "       -1.21086536e+00, -5.00000000e+09, -1.41421356e+00, -1.13567449e+00,\n",
       "       -1.00000000e+00, -1.17157288e+00, -1.28656609e+00, -1.22474487e+00,\n",
       "       -1.10355339e+00, -1.31392974e+00, -1.02160050e+00, -1.19841474e+00,\n",
       "       -1.10102051e+00, -1.17157288e+00])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = clf.negative_outlier_factor_\n",
    "df_scores[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.31662479e+10, -2.64575131e+10, -2.23606798e+10, -2.23606798e+10,\n",
       "       -2.00000000e+10, -1.73205081e+10, -1.73205081e+10, -1.73205081e+10,\n",
       "       -1.73205081e+10, -1.73205081e+10, -1.73205081e+10, -1.73205081e+10,\n",
       "       -1.73205081e+10, -1.73205081e+10, -1.73205081e+10, -1.49767620e+10,\n",
       "       -1.41421356e+10, -1.41421356e+10, -1.41421356e+10, -1.41421356e+10,\n",
       "       -1.41421356e+10, -1.41421356e+10, -1.41421356e+10, -1.41421356e+10,\n",
       "       -1.41421356e+10, -1.41421356e+10, -1.41421356e+10, -1.41421356e+10,\n",
       "       -1.41421356e+10, -1.41421356e+10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df_scores)[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value = np.sort(df_scores)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_tf = df_scores > threshold_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df_scores > threshold_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1Cresult and max_glu_serum\n",
    "df['A1Cresult'] = df['A1Cresult'].replace(['>7','>8','Norm','None'],[1,1,0,-99])\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace(['>200','>300','Norm','None'],[1,1,0,-99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot Encoding Race and Id's\n",
    "one_hot_data = pd.get_dummies(df, columns=['race'], prefix=[\"enc\"], drop_first = True)\n",
    "\n",
    "columns_ids = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id']\n",
    "\n",
    "one_hot_data[columns_ids] = one_hot_data[columns_ids].astype('str')\n",
    "one_hot_data = pd.get_dummies(one_hot_data, columns=columns_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = one_hot_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_cols = ['diag_1', 'diag_2', 'diag_3']\n",
    "\n",
    "df = pd.get_dummies(df, columns=diag_cols, prefix=[\"encdiag_1\", \"encdiag_2\", \"encdiag_3\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['encdiag_1_NAN', 'encdiag_2_NAN', 'encdiag_3_NAN']\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminando colunas com grande número de valores ausentes\n",
    "df = df.drop(['weight','payer_code','medical_specialty'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as linhas Unknown/Invalid da coluna gender\n",
    "df = df.loc[~df.gender.isin(['Unknown/Invalid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['citoglipton', 'examide'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numchange\n",
       "0    74056\n",
       "1    26272\n",
       "2     1318\n",
       "3      108\n",
       "4        5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
    "        'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'acarbose',\n",
    "        'miglitol', 'insulin', 'glyburide.metformin', 'tolazamide', 'metformin.pioglitazone',\n",
    "        'metformin.rosiglitazone', 'glimepiride.pioglitazone', 'glipizide.metformin',\n",
    "        'troglitazone', 'tolbutamide', 'acetohexamide']\n",
    "for col in keys:\n",
    "    colname = str(col) + 'temp'\n",
    "    df[colname] = df[col].apply(lambda x: 0 if (x == 'No' or x == 'Steady') else 1)\n",
    "df['numchange'] = 0\n",
    "for col in keys:\n",
    "    colname = str(col) + 'temp'\n",
    "    df['numchange'] = df['numchange'] + df[colname]\n",
    "    del df[colname]\n",
    "\n",
    "df['numchange'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['change'] = df['change'].replace('Ch', 1)\n",
    "df['change'] = df['change'].replace('No', 0)\n",
    "df['gender'] = df['gender'].replace('Male', 1)\n",
    "df['gender'] = df['gender'].replace('Female', 0)\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('Yes', 1)\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('No', 0)\n",
    "\n",
    "for col in keys:\n",
    "    df[col] = df[col].replace('No', 0)\n",
    "    df[col] = df[col].replace('Steady', 1)\n",
    "    df[col] = df[col].replace('Up', 1)\n",
    "    df[col] = df[col].replace('Down', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nummed\n",
       "1    47312\n",
       "0    23401\n",
       "2    21871\n",
       "3     7777\n",
       "4     1335\n",
       "5       58\n",
       "6        5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['nummed'] = 0\n",
    "\n",
    "for col in keys:\n",
    "    df['nummed'] = df['nummed'] + df[col]\n",
    "df['nummed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "8     26066\n",
       "7     22480\n",
       "6     17256\n",
       "9     17196\n",
       "5      9685\n",
       "4      3775\n",
       "10     2792\n",
       "3      1657\n",
       "2       691\n",
       "1       161\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformando os intervalos das idade em 1 - 10\n",
    "for i in range(0,10):\n",
    "    df['age'] = df['age'].replace('['+str(10*i)+'-'+str(10*(i+1))+')', i+1)\n",
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "8     26066\n",
      "7     22480\n",
      "6     17256\n",
      "9     17196\n",
      "5      9685\n",
      "4      3775\n",
      "10     2792\n",
      "3      1657\n",
      "2       691\n",
      "1       161\n",
      "Name: count, dtype: int64\n",
      "age\n",
      "75    26066\n",
      "65    22480\n",
      "55    17256\n",
      "85    17196\n",
      "45     9685\n",
      "35     3775\n",
      "95     2792\n",
      "25     1657\n",
      "15      691\n",
      "5       161\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['age'] = df['age'].astype('int64')\n",
    "print(df.age.value_counts())\n",
    "# convert age categories to mid-point values\n",
    "age_dict = {1:5, 2:15, 3:25, 4:35, 5:45, 6:55, 7:65, 8:75, 9:85, 10:95}\n",
    "df['age'] = df.age.map(age_dict)\n",
    "print(df.age.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactionterms = [('num_medications','time_in_hospital'),\n",
    "('num_medications','num_procedures'),\n",
    "('time_in_hospital','num_lab_procedures'),\n",
    "('num_medications','num_lab_procedures'),\n",
    "('num_medications','number_diagnoses'),\n",
    "('age','number_diagnoses'),\n",
    "('change','num_medications'),\n",
    "('number_diagnoses','time_in_hospital'),\n",
    "('num_medications','numchange')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inter in interactionterms:\n",
    "    name = inter[0] + '|' + inter[1]\n",
    "    df[name] = df[inter[0]] * df[inter[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_medications</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_medications|time_in_hospital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_medications  time_in_hospital  num_medications|time_in_hospital\n",
       "0               17                 4                                68\n",
       "1               10                 3                                30\n",
       "2                8                 2                                16\n",
       "3               12                 1                                12\n",
       "4               23                 3                                69"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['num_medications','time_in_hospital', 'num_medications|time_in_hospital']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = df.select_dtypes(include=['bool']).columns\n",
    "df[bool_cols] = df[bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
      "count      1.017590e+05        1.017590e+05    1.017590e+05     1.017590e+05   \n",
      "mean       5.586083e-18        8.281368e-17    1.927199e-17    -1.094872e-16   \n",
      "std        1.000005e+00        1.000005e+00    1.000005e+00     1.000005e+00   \n",
      "min       -1.137692e+00       -2.139670e+00   -7.853987e-01    -1.848262e+00   \n",
      "25%       -8.026939e-01       -6.148364e-01   -7.853987e-01    -7.409253e-01   \n",
      "50%       -1.326970e-01        4.592477e-02   -1.991639e-01    -1.257385e-01   \n",
      "75%        5.372998e-01        7.066860e-01    3.870708e-01     4.894483e-01   \n",
      "max        3.217287e+00        4.518770e+00    2.732010e+00     7.994727e+00   \n",
      "\n",
      "       number_outpatient  number_emergency  number_inpatient  \\\n",
      "count       1.017590e+05      1.017590e+05      1.017590e+05   \n",
      "mean        5.250918e-17     -6.703299e-18      2.122711e-17   \n",
      "std         1.000005e+00      1.000005e+00      1.000005e+00   \n",
      "min        -2.914724e-01     -2.126106e-01     -5.032979e-01   \n",
      "25%        -2.914724e-01     -2.126106e-01     -5.032979e-01   \n",
      "50%        -2.914724e-01     -2.126106e-01     -5.032979e-01   \n",
      "75%        -2.914724e-01     -2.126106e-01      2.885370e-01   \n",
      "max         3.284988e+01      8.146555e+01      1.612524e+01   \n",
      "\n",
      "       number_diagnoses        nummed  num_medications|time_in_hospital  \\\n",
      "count      1.017590e+05  1.017590e+05                      1.017590e+05   \n",
      "mean       1.368590e-16 -1.536173e-17                     -4.217492e-17   \n",
      "std        1.000005e+00  1.000005e+00                      1.000005e+00   \n",
      "min       -3.321707e+00 -1.282035e+00                     -1.167569e+00   \n",
      "25%       -7.357814e-01 -1.952875e-01                     -7.645749e-01   \n",
      "50%        2.985890e-01 -1.952875e-01                     -3.265377e-01   \n",
      "75%        8.157742e-01  8.914596e-01                      4.969722e-01   \n",
      "max        4.436071e+00  5.238448e+00                      3.300410e+00   \n",
      "\n",
      "       num_medications|num_procedures  time_in_hospital|num_lab_procedures  \\\n",
      "count                    1.017590e+05                         1.017590e+05   \n",
      "mean                     1.187043e-17                        -1.005495e-17   \n",
      "std                      1.000005e+00                         1.000005e+00   \n",
      "min                     -6.427330e-01                        -1.474467e+00   \n",
      "25%                     -6.427330e-01                        -8.682216e-01   \n",
      "50%                     -3.884493e-01                        -1.209884e-01   \n",
      "75%                      2.218314e-01                         7.813310e-01   \n",
      "max                      5.841500e+00                         2.120711e+00   \n",
      "\n",
      "       num_medications|num_lab_procedures  num_medications|number_diagnoses  \\\n",
      "count                        1.017590e+05                      1.017590e+05   \n",
      "mean                         2.848902e-17                      6.703299e-18   \n",
      "std                          1.000005e+00                      1.000005e+00   \n",
      "min                         -1.608920e+00                     -1.827313e+00   \n",
      "25%                         -8.896060e-01                     -7.696688e-01   \n",
      "50%                         -3.708542e-02                     -1.149369e-01   \n",
      "75%                          8.553971e-01                      7.412510e-01   \n",
      "max                          1.787842e+00                      2.453627e+00   \n",
      "\n",
      "       age|number_diagnoses  change|num_medications  \\\n",
      "count          1.017590e+05            1.017590e+05   \n",
      "mean          -1.312729e-16            3.184067e-17   \n",
      "std            1.000005e+00            1.000005e+00   \n",
      "min           -2.653939e+00           -7.779575e-01   \n",
      "25%           -6.586003e-01           -7.779575e-01   \n",
      "50%           -1.146354e-02           -7.779575e-01   \n",
      "75%            9.592416e-01            7.035918e-01   \n",
      "max            4.653314e+00            6.722386e+00   \n",
      "\n",
      "       number_diagnoses|time_in_hospital  num_medications|numchange  \n",
      "count                       1.017590e+05               1.017590e+05  \n",
      "mean                       -1.078114e-16              -7.038464e-17  \n",
      "std                         1.000005e+00               1.000005e+00  \n",
      "min                        -1.249960e+00              -5.038498e-01  \n",
      "25%                        -7.180871e-01              -5.038498e-01  \n",
      "50%                        -2.621962e-01              -5.038498e-01  \n",
      "75%                         4.216401e-01               3.170667e-01  \n",
      "max                         6.614158e+00               1.536720e+01  \n"
     ]
    }
   ],
   "source": [
    "# Colunas numéricas\n",
    "numeric_cols = [\n",
    "    'time_in_hospital',\n",
    "    'num_lab_procedures',\n",
    "    'num_procedures',\n",
    "    'num_medications',\n",
    "    'number_outpatient',\n",
    "    'number_emergency',\n",
    "    'number_inpatient',\n",
    "    'number_diagnoses',\n",
    "    'nummed',\n",
    "    'num_medications|time_in_hospital',\n",
    "    'num_medications|num_procedures',\n",
    "    'time_in_hospital|num_lab_procedures',\n",
    "    'num_medications|num_lab_procedures',\n",
    "    'num_medications|number_diagnoses',\n",
    "    'age|number_diagnoses',\n",
    "    'change|num_medications',\n",
    "    'number_diagnoses|time_in_hospital',\n",
    "    'num_medications|numchange'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "print(df[numeric_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição no conjunto de treino:\n",
      "class\n",
      "0    0.888396\n",
      "1    0.111604\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribuição no conjunto de validação:\n",
      "class\n",
      "0    0.888365\n",
      "1    0.111635\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribuição no conjunto de teste:\n",
      "class\n",
      "0    0.888414\n",
      "1    0.111586\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Tamanho do conjunto de treino: X_train=(61055, 125), y_train=(61055,)\n",
      "Tamanho do conjunto de validação: X_val=(20352, 125), y_val=(20352,)\n",
      "Tamanho do conjunto de teste: X_test=(20352, 125), y_test=(20352,)\n",
      "Tamanho treino: 60.00%\n",
      "Tamanho validação: 20.00%\n",
      "Tamanho teste: 20.00%\n",
      "\n",
      "Arquivos CSV salvos com sucesso:\n",
      "- train_data.csv\n",
      "- validation_data.csv\n",
      "- test_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Selecionar as features e a variável target\n",
    "feature_set = [col for col in df.columns if col != 'class']\n",
    "X = df[feature_set]\n",
    "y = df['class']\n",
    "\n",
    "# Divisão treino (60%) e teste (20%) e validação (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n",
    "\n",
    "# Exibir as distribuições das classes em cada conjunto\n",
    "print(\"Distribuição no conjunto de treino:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribuição no conjunto de validação:\")\n",
    "print(y_val.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribuição no conjunto de teste:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "# Exibir os tamanhos de cada conjunto\n",
    "print(f\"\\nTamanho do conjunto de treino: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"Tamanho do conjunto de validação: X_val={X_val.shape}, y_val={y_val.shape}\")\n",
    "print(f\"Tamanho do conjunto de teste: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
    "\n",
    "print(f\"Tamanho treino: {len(X_train) / len(X):.2%}\")\n",
    "print(f\"Tamanho validação: {len(X_val) / len(X):.2%}\")\n",
    "print(f\"Tamanho teste: {len(X_test) / len(X):.2%}\")\n",
    "\n",
    "# Salvar os conjuntos em arquivos CSV\n",
    "# Concatenar X_train com y_train\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "\n",
    "# Concatenar X_val com y_val\n",
    "validation_data = pd.concat([X_val, y_val], axis=1)\n",
    "validation_data.to_csv(\"validation_data.csv\", index=False)\n",
    "\n",
    "# Concatenar X_test com y_test\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data.to_csv(\"test_data.csv\", index=False)\n",
    "\n",
    "print(\"\\nArquivos CSV salvos com sucesso:\")\n",
    "print(\"- train_data.csv\")\n",
    "print(\"- validation_data.csv\")\n",
    "print(\"- test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem e Otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os conjuntos de dados de treinamento, validação e teste\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "validation_data = pd.read_csv('validation_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando features e target no conjunto de treinamento\n",
    "X_train = train_data.drop('class', axis=1)\n",
    "y_train = train_data['class']\n",
    "\n",
    "# Separando features e target no conjunto de validação\n",
    "X_val = validation_data.drop('class', axis=1)\n",
    "y_val = validation_data['class']\n",
    "\n",
    "# Separando features e target no conjunto de teste\n",
    "X_test = test_data.drop('class', axis=1)\n",
    "y_test = test_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição das classes no conjunto de treinamento após o ADASYN:\n",
      "Counter({0: 54241, 1: 53008})\n"
     ]
    }
   ],
   "source": [
    "# Aplicando o ADASYN no conjunto de treinamento\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train, y_train = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Distribuição das classes no conjunto de treinamento após o ADASYN:')\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para avaliar o modelo utilizando validação cruzada estratificada com k=10\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    # Cálculo da ACSA\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    acsa = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "    print(f\"{model_name} - Acurácia: {acc:.4f}, F1-Score: {f1:.4f}, Recall: {recall:.4f}, ACSA: {acsa:.4f}\")\n",
    "    \n",
    "    # Plotando a matriz de confusão\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Matriz de Confusão - {model_name}')\n",
    "    plt.xlabel('Predito')\n",
    "    plt.ylabel('Real')\n",
    "    plt.show()\n",
    "    \n",
    "    # Imprimindo o relatório de classificação\n",
    "    print(f\"Relatório de Classificação para {model_name}:\\n\", classification_report(y_val, y_pred))\n",
    "    \n",
    "    # Plotando a curva ROC, se possível\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_val)[:,1]\n",
    "        fpr, tpr, thresholds = roc_curve(y_val, y_prob)\n",
    "        roc_auc = roc_auc_score(y_val, y_prob)\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "        plt.plot([0,1], [0,1], 'k--')\n",
    "        plt.title(f'Curva ROC - {model_name}')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"{model_name} não suporta predict_proba, curva ROC não será plotada.\")\n",
    "    \n",
    "    return acc, f1, recall, acsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os modelos\n",
    "# Dicionário para armazenar os modelos\n",
    "models = {\n",
    "    'K-NN': KNeighborsClassifier(),\n",
    "    'LVQ': NearestCentroid(),\n",
    "    'Árvore de Decisão': DecisionTreeClassifier(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Rede Neural MLP': MLPClassifier(max_iter=500),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': LGBMClassifier()\n",
    "}\n",
    "\n",
    "# Comitê de Redes Neurais Artificiais\n",
    "nn1 = MLPClassifier(hidden_layer_sizes=(50,), activation='relu', solver='adam', max_iter=500, random_state=1)\n",
    "nn2 = MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', solver='sgd', max_iter=500, random_state=2)\n",
    "nn3 = MLPClassifier(hidden_layer_sizes=(50, 50), activation='relu', solver='adam', max_iter=500, random_state=3)\n",
    "\n",
    "committee_nn = VotingClassifier(estimators=[\n",
    "    ('nn1', nn1),\n",
    "    ('nn2', nn2),\n",
    "    ('nn3', nn3)\n",
    "], voting='soft')\n",
    "\n",
    "models['Comitê de Redes Neurais Artificiais'] = committee_nn\n",
    "\n",
    "# Comitê Heterogêneo (Stacking)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svm', SVC(probability=True, random_state=42)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "stacking_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
    "\n",
    "models['Comitê Heterogêneo (Stacking)'] = stacking_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 11:14:32,287] A new study created in memory with name: K-NN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otimização para o modelo: K-NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 11:14:50,479] Trial 0 finished with value: 0.6984866944639428 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'algorithm': 'auto'}. Best is trial 0 with value: 0.6984866944639428.\n",
      "[I 2024-11-30 11:15:08,977] A new study created in memory with name: LVQ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otimização para o modelo: LVQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 11:15:11,655] Trial 0 finished with value: 0.6058612498819502 and parameters: {'metric': 'manhattan', 'use_shrinkage': True, 'shrink_threshold': 0.15601864044243652}. Best is trial 0 with value: 0.6058612498819502.\n",
      "[I 2024-11-30 11:15:15,362] A new study created in memory with name: Árvore de Decisão\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otimização para o modelo: Árvore de Decisão\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 11:15:18,588] Trial 0 finished with value: 0.8017233767832863 and parameters: {'max_depth': 8, 'min_samples_split': 10, 'criterion': 'gini'}. Best is trial 0 with value: 0.8017233767832863.\n",
      "[I 2024-11-30 11:15:27,162] A new study created in memory with name: SVM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otimização para o modelo: SVM\n"
     ]
    }
   ],
   "source": [
    "# Otimização de hiperparâmetros com Optuna\n",
    "# Configurando o Callback do MLflow para o Optuna\n",
    "mlflc = MLflowCallback(tracking_uri=mlflow.get_tracking_uri(), metric_name='accuracy')\n",
    "\n",
    "# Definindo funções auxiliares para construção e otimização dos modelos\n",
    "def build_classifier(model_name, params):\n",
    "    if model_name == 'K-NN':\n",
    "        classifier = KNeighborsClassifier(\n",
    "            n_neighbors=params['n_neighbors'],\n",
    "            weights=params['weights'],\n",
    "            algorithm=params['algorithm']\n",
    "        )\n",
    "    elif model_name == 'LVQ':\n",
    "        classifier = NearestCentroid(\n",
    "            metric=params['metric'],\n",
    "            shrink_threshold=params['shrink_threshold']\n",
    "        )\n",
    "    elif model_name == 'Árvore de Decisão':\n",
    "        classifier = DecisionTreeClassifier(\n",
    "            max_depth=params['max_depth'],\n",
    "            min_samples_split=params['min_samples_split'],\n",
    "            criterion=params['criterion']\n",
    "        )\n",
    "    elif model_name == 'SVM':\n",
    "        classifier = SVC(\n",
    "            C=params['C'],\n",
    "            kernel=params['kernel'],\n",
    "            gamma=params['gamma']\n",
    "        )\n",
    "    elif model_name == 'Random Forest':\n",
    "        classifier = RandomForestClassifier(\n",
    "            n_estimators=params['n_estimators'],\n",
    "            max_depth=params['max_depth'],\n",
    "            min_samples_split=params['min_samples_split']\n",
    "        )\n",
    "    elif model_name == 'Rede Neural MLP':\n",
    "        classifier = MLPClassifier(\n",
    "            hidden_layer_sizes=params['hidden_layer_sizes'],\n",
    "            activation=params['activation'],\n",
    "            solver=params['solver'],\n",
    "            alpha=params['alpha'],\n",
    "            max_iter=500\n",
    "        )\n",
    "    elif model_name == 'Comitê de Redes Neurais Artificiais':\n",
    "        nn1 = MLPClassifier(\n",
    "            hidden_layer_sizes=params['hidden_layer_sizes'],\n",
    "            activation=params['activation'],\n",
    "            solver=params['solver'],\n",
    "            max_iter=500,\n",
    "            random_state=1\n",
    "        )\n",
    "        nn2 = MLPClassifier(\n",
    "            hidden_layer_sizes=params['hidden_layer_sizes'],\n",
    "            activation=params['activation'],\n",
    "            solver=params['solver'],\n",
    "            max_iter=500,\n",
    "            random_state=2\n",
    "        )\n",
    "        nn3 = MLPClassifier(\n",
    "            hidden_layer_sizes=params['hidden_layer_sizes'],\n",
    "            activation=params['activation'],\n",
    "            solver=params['solver'],\n",
    "            max_iter=500,\n",
    "            random_state=3\n",
    "        )\n",
    "        classifier = VotingClassifier(\n",
    "            estimators=[\n",
    "                ('nn1', nn1),\n",
    "                ('nn2', nn2),\n",
    "                ('nn3', nn3)\n",
    "            ],\n",
    "            voting='soft'\n",
    "        )\n",
    "    elif model_name == 'Comitê Heterogêneo (Stacking)':\n",
    "        final_estimator = LogisticRegression(\n",
    "            C=params['C'],\n",
    "            penalty=params['penalty'],\n",
    "            solver=params['solver']\n",
    "        )\n",
    "        estimators = [\n",
    "            ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "            ('svm', SVC(random_state=42)),\n",
    "            ('knn', KNeighborsClassifier())\n",
    "        ]\n",
    "        classifier = StackingClassifier(\n",
    "            estimators=estimators,\n",
    "            final_estimator=final_estimator,\n",
    "            cv=5\n",
    "        )\n",
    "    elif model_name == 'XGBoost':\n",
    "        classifier = XGBClassifier(\n",
    "            n_estimators=params['n_estimators'],\n",
    "            max_depth=params['max_depth'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            subsample=params['subsample'],\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss'\n",
    "        )\n",
    "    elif model_name == 'LightGBM':\n",
    "        classifier = LGBMClassifier(\n",
    "            n_estimators=params['n_estimators'],\n",
    "            num_leaves=params['num_leaves'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            subsample=params['subsample']\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Modelo {model_name} não reconhecido.\")\n",
    "    return classifier\n",
    "\n",
    "def objective_factory(model_name):\n",
    "    def objective(trial):\n",
    "        params = {}\n",
    "        # Definir os hiperparâmetros para cada modelo\n",
    "        if model_name == 'K-NN':\n",
    "            params['n_neighbors'] = trial.suggest_int('n_neighbors', 1, 30)\n",
    "            params['weights'] = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "            params['algorithm'] = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "        \n",
    "        elif model_name == 'LVQ':\n",
    "            params['metric'] = trial.suggest_categorical('metric', ['euclidean', 'manhattan'])\n",
    "            use_shrinkage = trial.suggest_categorical('use_shrinkage', [True, False])\n",
    "            params['shrink_threshold'] = trial.suggest_float('shrink_threshold', 0.0, 1.0) if use_shrinkage else None\n",
    "        \n",
    "        elif model_name == 'Árvore de Decisão':\n",
    "            params['max_depth'] = trial.suggest_int('max_depth', 1, 20)\n",
    "            params['min_samples_split'] = trial.suggest_int('min_samples_split', 2, 10)\n",
    "            params['criterion'] = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "        \n",
    "        elif model_name == 'SVM':\n",
    "            params['C'] = trial.suggest_float('C', 0.1, 10.0, log=True)\n",
    "            params['kernel'] = trial.suggest_categorical('kernel', ['linear', 'rbf'])\n",
    "            params['gamma'] = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "        \n",
    "        elif model_name == 'Random Forest':\n",
    "            params['n_estimators'] = trial.suggest_int('n_estimators', 50, 300)\n",
    "            params['max_depth'] = trial.suggest_int('max_depth', 2, 20)\n",
    "            params['min_samples_split'] = trial.suggest_int('min_samples_split', 2, 10)\n",
    "        \n",
    "        elif model_name == 'Rede Neural MLP':\n",
    "            params['hidden_layer_sizes'] = trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50,50)])\n",
    "            params['activation'] = trial.suggest_categorical('activation', ['tanh', 'relu'])\n",
    "            params['solver'] = trial.suggest_categorical('solver', ['sgd', 'adam'])\n",
    "            params['alpha'] = trial.suggest_float('alpha', 1e-5, 1e-1, log=True)\n",
    "        \n",
    "        elif model_name == 'Comitê de Redes Neurais Artificiais':\n",
    "            params['hidden_layer_sizes'] = trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50,50)])\n",
    "            params['activation'] = trial.suggest_categorical('activation', ['tanh', 'relu'])\n",
    "            params['solver'] = trial.suggest_categorical('solver', ['sgd', 'adam'])\n",
    "        \n",
    "        elif model_name == 'Comitê Heterogêneo (Stacking)':\n",
    "            params['C'] = trial.suggest_float('C', 0.1, 10.0, log=True)\n",
    "            params['penalty'] = trial.suggest_categorical('penalty', ['l2'])\n",
    "            params['solver'] = trial.suggest_categorical('solver', ['lbfgs'])\n",
    "        \n",
    "        elif model_name == 'XGBoost':\n",
    "            params['n_estimators'] = trial.suggest_int('n_estimators', 50, 300)\n",
    "            params['max_depth'] = trial.suggest_int('max_depth', 3, 15)\n",
    "            params['learning_rate'] = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "            params['subsample'] = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "        \n",
    "        elif model_name == 'LightGBM':\n",
    "            params['n_estimators'] = trial.suggest_int('n_estimators', 50, 300)\n",
    "            params['num_leaves'] = trial.suggest_int('num_leaves', 31, 150)\n",
    "            params['learning_rate'] = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "            params['subsample'] = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Modelo {model_name} não reconhecido.\")\n",
    "        \n",
    "        # Treinando no conjunto de treinamento balanceado\n",
    "        # classifier.fit(X_train, y_train)\n",
    "        # # Avaliando no conjunto de validação\n",
    "        # y_pred_val = classifier.predict(X_val)\n",
    "        # acc = accuracy_score(y_val, y_pred_val)\n",
    "        classifier = build_classifier(model_name, params)\n",
    "        \n",
    "        acc = cross_val_score(classifier, X_train, y_train, scoring='accuracy', n_jobs=-1).mean()\n",
    "        return acc\n",
    "    return objective\n",
    "\n",
    "# Executando as Otimizações com Optuna para SVM e Random Forest\n",
    "n_trials = 1  # Número de iterações\n",
    "\n",
    "best_models = {}\n",
    "best_params = {}\n",
    "cv_results = {}\n",
    "# models_to_optimize = ['K-NN', 'Random Forest']\n",
    "\n",
    "for model_name in models.keys():\n",
    "    print(f\"Otimização para o modelo: {model_name}\")\n",
    "    study = optuna.create_study(direction='maximize', study_name=model_name, sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    study.optimize(objective_factory(model_name), n_trials=n_trials, callbacks=[mlflc])\n",
    "    \n",
    "    # Armazenando os melhores hiperparâmetros\n",
    "    best_params[model_name] = study.best_params\n",
    "    \n",
    "    # Criando o classificador com os melhores hiperparâmetros\n",
    "    classifier = build_classifier(model_name, best_params[model_name])\n",
    "    \n",
    "    # Armazenando o classificador otimizado\n",
    "    best_models[model_name] = classifier\n",
    "    \n",
    "    # Armazenando os scores dos folds\n",
    "    acc_scores = cross_val_score(classifier, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_results[model_name] = acc_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN - Acurácia Média: 0.7505, F1-Score Médio: 0.7975, Recall Médio: 0.9941, ACSA Média: 0.7533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/30 01:38:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Acurácia Média: 0.9067, F1-Score Médio: 0.8701, Recall Médio: 0.8581, ACSA Média: 0.9061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/30 01:43:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Modelo  Acurácia  F1-Score    Recall      ACSA\n",
      "0           K-NN  0.750477  0.797460  0.994097  0.753309\n",
      "1  Random Forest  0.906664  0.870065  0.858084  0.906096\n"
     ]
    }
   ],
   "source": [
    "# Avaliando os modelos otimizados\n",
    "# results = []\n",
    "\n",
    "# for model_name, model in best_models.items():\n",
    "#     with mlflow.start_run(run_name=f\"{model_name} - Optuna HPO\"):\n",
    "#         acc, f1, recall, acsa = evaluate_model(model, X_train, y_train, model_name)\n",
    "#         mlflow.log_params(best_params[model_name])\n",
    "#         mlflow.log_metric(\"accuracy\", acc)\n",
    "#         mlflow.log_metric(\"f1_score\", f1)\n",
    "#         mlflow.log_metric(\"recall\", recall)\n",
    "#         mlflow.log_metric(\"acsa\", acsa)\n",
    "#         # Salvar o modelo\n",
    "#         mlflow.sklearn.log_model(model, model_name)\n",
    "#         results.append({\n",
    "#             'Modelo': model_name,\n",
    "#             'Acurácia': acc,\n",
    "#             'F1-Score': f1,\n",
    "#             'Recall': recall,\n",
    "#             'ACSA': acsa\n",
    "#         })\n",
    "\n",
    "# # Converte os resultados em DataFrame\n",
    "# optimized_results_df = pd.DataFrame(results)\n",
    "\n",
    "# # Exibindo os resultados dos modelos otimizados\n",
    "# print(optimized_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN - Acurácia Média: 0.7505, F1-Score Médio: 0.7975, Recall Médio: 0.9941, ACSA Média: 0.7533\n",
      "LVQ - Acurácia Média: 0.5075, F1-Score Médio: 0.6171, Recall Médio: 0.8032, ACSA Média: 0.5109\n",
      "Árvore de Decisão - Acurácia Média: 0.8518, F1-Score Médio: 0.8291, Recall Médio: 0.8499, ACSA Média: 0.8518\n"
     ]
    }
   ],
   "source": [
    "# Avaliando todos os modelos\n",
    "# final_results = []\n",
    "\n",
    "# for model_name, model in models.items():\n",
    "#     if model_name in best_models:\n",
    "#         # Usar o modelo otimizado\n",
    "#         model = best_models[model_name]\n",
    "#     else:\n",
    "#         # Usar o modelo padrão\n",
    "#         model = model\n",
    "#     acc, f1, recall, acsa = evaluate_model(model, X_train, y_train.values, model_name)\n",
    "#     final_results.append({\n",
    "#         'Modelo': model_name,\n",
    "#         'Acurácia': acc,\n",
    "#         'F1-Score': f1,\n",
    "#         'Recall': recall,\n",
    "#         'ACSA': acsa\n",
    "#     })\n",
    "\n",
    "# # Convertendo para DataFrame\n",
    "# final_results_df = pd.DataFrame(final_results)\n",
    "\n",
    "# # Exibindo os resultados finais\n",
    "# print(final_results_df)\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run(run_name=f\"{model_name} - Avaliação Final\"):\n",
    "        acc, f1, recall, acsa = evaluate_model(model, X_train, y_train, X_val, y_val, model_name)\n",
    "        mlflow.log_params(best_params[model_name])\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"acsa\", acsa)\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        final_results.append({\n",
    "            'Modelo': model_name,\n",
    "            'Acurácia': acc,\n",
    "            'F1-Score': f1,\n",
    "            'Recall': recall,\n",
    "            'ACSA': acsa\n",
    "        })\n",
    "\n",
    "# Convertendo para DataFrame\n",
    "final_results_df = pd.DataFrame(final_results)\n",
    "\n",
    "# Exibindo os resultados finais\n",
    "print(final_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando as métricas\n",
    "final_results_melted = final_results_df.melt(id_vars='Modelo', value_vars=['Acurácia', 'F1-Score', 'Recall', 'ACSA'], var_name='Métrica', value_name='Valor')\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x='Modelo', y='Valor', hue='Métrica', data=final_results_melted)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Comparação das Métricas dos Modelos')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Usando os scores de validação cruzada\n",
    "# model_scores = {}\n",
    "\n",
    "# for model_name, model in models.items():\n",
    "#     if model_name in best_models:\n",
    "#         model = best_models[model_name]\n",
    "#     else:\n",
    "#         model = model\n",
    "#     skf = StratifiedKFold(n_splits=10)\n",
    "#     scores = cross_val_score(model, X_train, y_train.values, cv=skf, scoring='accuracy')\n",
    "#     model_scores[model_name] = scores\n",
    "\n",
    "# # Criando DataFrame com os scores\n",
    "# scores_df = pd.DataFrame(model_scores)\n",
    "\n",
    "# # Teste de Friedman\n",
    "# stat, p = friedmanchisquare(*[scores_df[model] for model in scores_df.columns])\n",
    "# print(f'Estatística de Friedman: {stat}, p-valor: {p}')\n",
    "\n",
    "# # Se p-valor < 0.05, há diferença significativa\n",
    "# if p < 0.05:\n",
    "#     print('Diferença significativa entre os modelos. Realizando teste de Nemenyi.')\n",
    "#     nemenyi = sp.posthoc_nemenyi_friedman(scores_df.values)\n",
    "#     nemenyi_df = pd.DataFrame(nemenyi, index=scores_df.columns, columns=scores_df.columns)\n",
    "#     print(nemenyi_df)\n",
    "# else:\n",
    "#     print('Não há diferença significativa entre os modelos.')\n",
    "\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "metricas = ['Acurácia', 'F1-Score', 'Recall', 'ACSA']\n",
    "\n",
    "for metrica in metricas:\n",
    "    print(f\"\\nAnálise Estatística para a Métrica: {metrica}\")\n",
    "    # Pivotando o DataFrame\n",
    "    pivot_df = cv_results_df.pivot(index='Fold', columns='Modelo', values=metrica)\n",
    "    \n",
    "    # Removendo modelos que não possuem valores (caso haja)\n",
    "    pivot_df = pivot_df.dropna(axis=1, how='any')\n",
    "    \n",
    "    # Aplicando o teste de Friedman\n",
    "    stat, p = friedmanchisquare(*[pivot_df[model] for model in pivot_df.columns])\n",
    "    print(f'Estatística de Friedman: {stat}, p-valor: {p}')\n",
    "    \n",
    "    # Se p-valor < 0.05, há diferença significativa\n",
    "    if p < 0.05:\n",
    "        print('Diferença significativa entre os modelos. Realizando teste de Nemenyi.')\n",
    "        nemenyi = sp.posthoc_nemenyi_friedman(pivot_df.values)\n",
    "        nemenyi_df = pd.DataFrame(nemenyi, index=pivot_df.columns, columns=pivot_df.columns)\n",
    "        print(nemenyi_df)\n",
    "    else:\n",
    "        print(f'Não há diferença significativa entre os modelos para a métrica {metrica}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Custo-Benefício"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_benefit_results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name in best_models:\n",
    "        model = best_models[model_name]\n",
    "    else:\n",
    "        model = model\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train.values)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    mem_usage = sys.getsizeof(model)\n",
    "    cost_benefit_results.append({\n",
    "        'Modelo': model_name,\n",
    "        'Tempo de Treinamento (s)': training_time,\n",
    "        'Uso de Memória (bytes)': mem_usage\n",
    "    })\n",
    "\n",
    "# Convertendo para DataFrame\n",
    "cost_benefit_df = pd.DataFrame(cost_benefit_results)\n",
    "\n",
    "# Exibindo os resultados\n",
    "print(cost_benefit_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando o tempo de treinamento\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Modelo', y='Tempo de Treinamento (s)', data=cost_benefit_df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Tempo de Treinamento dos Modelos')\n",
    "plt.show()\n",
    "\n",
    "# Plotando o uso de memória\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Modelo', y='Uso de Memória (bytes)', data=cost_benefit_df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Uso de Memória dos Modelos')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste de Estresse dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando o conjunto de teste para o teste de estresse\n",
    "stress_test_results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name in best_models:\n",
    "        model = best_models[model_name]\n",
    "    else:\n",
    "        model = model\n",
    "    # Avaliando no conjunto de teste\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    # Cálculo da ACSA\n",
    "    cm = confusion_matrix(y_test, y_pred_test)\n",
    "    acsa_test = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "    stress_test_results.append({\n",
    "        'Modelo': model_name,\n",
    "        'Acurácia': acc_test,\n",
    "        'F1-Score': f1_test,\n",
    "        'Recall': recall_test,\n",
    "        'ACSA': acsa_test\n",
    "    })\n",
    "\n",
    "# Convertendo para DataFrame\n",
    "stress_test_df = pd.DataFrame(stress_test_results)\n",
    "\n",
    "# Exibindo os resultados\n",
    "print(stress_test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussão sobre Limitações e Futuras Melhorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências\n",
    "\n",
    "Tom Fawcett and Foster Provost. Data Science for Business. O’Reilly Media Inc., 08/2013.\n",
    "\n",
    "Micheline Kamber Jiawei Han and Jian Pei. Data Mining: Concepts and Techniques. Data Management Systems, 2012.\n",
    "\n",
    "PNS. Pesquisa nacional de saúde: 2019: percepção do estado de saúde, estilos de vida, doenças crônicas e saúde bucal: Brasil e grandes regiões. IBGE, Rio de Janeiro, 2019. URL https://www.pns.icict.fiocruz.br/wp-content/uploads/2021/ 02/liv101764.pdf. Convênio: Ministério da Saúde. Inclui bibliografia e glossário. ISBN 978-65-87201-33-7.\n",
    "\n",
    "World Health Organization (WHO). Diabetes factsheet, 2020. URL https://www.who.int/news-room/fact-sheets/detail/diabetes. [acessado em 04 de novembro de 2024]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
