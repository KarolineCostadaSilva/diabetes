{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as Bibliotecas Necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modelos\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Validação e métricas\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Bibliotecas adicionais\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando o MLflow\n",
    "mlflow.set_experiment(\"Modelagem de Classificação com Optuna\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os conjuntos de dados\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "validation_data = pd.read_csv('validation_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando features e target no conjunto de treinamento\n",
    "X_train = train_data.drop('class', axis=1)\n",
    "y_train = train_data['class']\n",
    "\n",
    "# Separando features e target no conjunto de validação\n",
    "X_val = validation_data.drop('class', axis=1)\n",
    "y_val = validation_data['class']\n",
    "\n",
    "# Conjunto de teste\n",
    "X_test = test_data.drop('class', axis=1)\n",
    "y_test = test_data['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo uma Função de Avaliação\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "    recall = recall_score(y_val, y_pred, average='weighted')\n",
    "    y_prob = model.predict_proba(X_val)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    roc_auc = roc_auc_score(y_val, y_prob) if y_prob is not None else None\n",
    "    return acc, f1, recall, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os Modelos\n",
    "models = {\n",
    "    'K-NN': KNeighborsClassifier(),\n",
    "    'LVQ': NearestCentroid(),\n",
    "    'Árvore de Decisão': DecisionTreeClassifier(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Rede Neural MLP': MLPClassifier(max_iter=500),\n",
    "    'Comitê de Redes Neurais Artificiais': None,  # Será definido posteriormente\n",
    "    'Comitê Heterogêneo (Stacking)': None,       # Será definido posteriormente\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': LGBMClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comitê de Redes Neurais Artificiais\n",
    "# Definindo múltiplas redes neurais\n",
    "nn1 = MLPClassifier(hidden_layer_sizes=(50,), activation='relu', solver='adam', max_iter=500, random_state=1)\n",
    "nn2 = MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', solver='sgd', max_iter=500, random_state=2)\n",
    "nn3 = MLPClassifier(hidden_layer_sizes=(50, 50), activation='relu', solver='adam', max_iter=500, random_state=3)\n",
    "\n",
    "# Criando o Comitê\n",
    "committee_nn = VotingClassifier(estimators=[\n",
    "    ('nn1', nn1),\n",
    "    ('nn2', nn2),\n",
    "    ('nn3', nn3)\n",
    "], voting='soft')\n",
    "\n",
    "models['Comitê de Redes Neurais Artificiais'] = committee_nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comitê Heterogêneo (Stacking)\n",
    "# Modelos base\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svm', SVC(probability=True, random_state=42)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "# Modelo meta\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "# Criando o StackingClassifier\n",
    "stacking_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
    "\n",
    "models['Comitê Heterogêneo (Stacking)'] = stacking_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executando os Modelos Básicos e Registrando no MLflow\n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        acc, f1, recall, roc_auc = evaluate_model(model, X_train, y_train, X_val, y_val)\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        if roc_auc is not None:\n",
    "            mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        # Salvar o modelo\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        print(f\"{model_name} - Acurácia: {acc}, F1-Score: {f1}, Recall: {recall}, ROC AUC: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca de Hiperparâmetros com Optuna\n",
    "# Configurando o Callback do MLflow para o Optuna\n",
    "mlflc = MLflowCallback(tracking_uri=mlflow.get_tracking_uri(), metric_name='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-NN\n",
    "def objective_knn(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 30)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm)\n",
    "    acc = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Árvore de Decisão\n",
    "def objective_decision_tree(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    \n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, criterion=criterion)\n",
    "    acc = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "def objective_svm(trial):\n",
    "    C = trial.suggest_float('C', 0.1, 10.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    \n",
    "    model = SVC(C=C, kernel=kernel, gamma=gamma)\n",
    "    acc = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def objective_random_forest(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "    acc = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede Neural MLP\n",
    "def objective_mlp(trial):\n",
    "    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50,50)])\n",
    "    activation = trial.suggest_categorical('activation', ['tanh', 'relu'])\n",
    "    solver = trial.suggest_categorical('solver', ['sgd', 'adam'])\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
    "    \n",
    "    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, alpha=alpha, max_iter=500)\n",
    "    acc = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comitê de Redes Neurais Artificiais\n",
    "def objective_committee_nn(trial):\n",
    "    # Hiperparâmetros para as redes individuais\n",
    "    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50,50)])\n",
    "    activation = trial.suggest_categorical('activation', ['tanh', 'relu'])\n",
    "    solver = trial.suggest_categorical('solver', ['sgd', 'adam'])\n",
    "    \n",
    "    # Definindo as redes neurais\n",
    "    nn1 = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, max_iter=500, random_state=1)\n",
    "    nn2 = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, max_iter=500, random_state=2)\n",
    "    nn3 = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, max_iter=500, random_state=3)\n",
    "    \n",
    "    # Comitê\n",
    "    committee_nn = VotingClassifier(estimators=[\n",
    "        ('nn1', nn1),\n",
    "        ('nn2', nn2),\n",
    "        ('nn3', nn3)\n",
    "    ], voting='soft')\n",
    "    \n",
    "    acc = cross_val_score(committee_nn, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comitê Heterogêneo (Stacking)\n",
    "def objective_stacking(trial):\n",
    "    # Hiperparâmetros do estimador final\n",
    "    C = trial.suggest_loguniform('C', 1e-3, 1e3)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2'])\n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs'])\n",
    "    \n",
    "    final_estimator = LogisticRegression(C=C, penalty=penalty, solver=solver)\n",
    "    \n",
    "    # Modelos base (podemos também ajustar seus hiperparâmetros se desejado)\n",
    "    estimators = [\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('svm', SVC(probability=True, random_state=42)),\n",
    "        ('knn', KNeighborsClassifier())\n",
    "    ]\n",
    "    \n",
    "    stacking_model = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
    "    \n",
    "    acc = cross_val_score(stacking_model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "def objective_xgboost(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    acc = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "def objective_lightgbm(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    num_leaves = trial.suggest_int('num_leaves', 31, 150)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    \n",
    "    model = LGBMClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        num_leaves=num_leaves,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample\n",
    "    )\n",
    "    acc = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executando as Otimizações com Optuna\n",
    "n_trials = 5  # Número de iterações\n",
    "\n",
    "# Dicionário para armazenar os melhores modelos\n",
    "best_models = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-NN\n",
    "study_knn = optuna.create_study(direction='maximize') # , study_name='Modelagem', sampler=optuna.samplers.TPESampler(seed=123)\n",
    "study_knn.optimize(objective_knn, n_trials=n_trials, callbacks=[mlflc])\n",
    "best_knn = KNeighborsClassifier(**study_knn.best_params)\n",
    "best_models['K-NN'] = best_knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Árvore de Decisão\n",
    "study_dt = optuna.create_study(direction='maximize')\n",
    "study_dt.optimize(objective_decision_tree, n_trials=n_trials, callbacks=[mlflc])\n",
    "best_dt = DecisionTreeClassifier(**study_dt.best_params)\n",
    "best_models['Árvore de Decisão'] = best_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "study_svm = optuna.create_study(direction='maximize')\n",
    "study_svm.optimize(objective_svm, n_trials=n_trials, callbacks=[mlflc])\n",
    "best_svm = SVC(probability=True, **study_svm.best_params)\n",
    "best_models['SVM'] = best_svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(objective_random_forest, n_trials=n_trials, callbacks=[mlflc])\n",
    "best_rf = RandomForestClassifier(**study_rf.best_params)\n",
    "best_models['Random Forest'] = best_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede Neural MLP\n",
    "study_mlp = optuna.create_study(direction='maximize')\n",
    "study_mlp.optimize(objective_mlp, n_trials=n_trials, callbacks=[mlflc])\n",
    "best_mlp = MLPClassifier(**study_mlp.best_params, max_iter=500)\n",
    "best_models['Rede Neural MLP'] = best_mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comitê de Redes Neurais Artificiais\n",
    "study_committee_nn = optuna.create_study(direction='maximize')\n",
    "study_committee_nn.optimize(objective_committee_nn, n_trials=n_trials, callbacks=[mlflc])\n",
    "\n",
    "# Usando os melhores hiperparâmetros\n",
    "hidden_layer_sizes = study_committee_nn.best_params['hidden_layer_sizes']\n",
    "activation = study_committee_nn.best_params['activation']\n",
    "solver = study_committee_nn.best_params['solver']\n",
    "\n",
    "# Definindo as redes neurais\n",
    "nn1 = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, max_iter=500, random_state=1)\n",
    "nn2 = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, max_iter=500, random_state=2)\n",
    "nn3 = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, max_iter=500, random_state=3)\n",
    "\n",
    "best_committee_nn = VotingClassifier(estimators=[\n",
    "    ('nn1', nn1),\n",
    "    ('nn2', nn2),\n",
    "    ('nn3', nn3)\n",
    "], voting='soft')\n",
    "\n",
    "best_models['Comitê de Redes Neurais Artificiais'] = best_committee_nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comitê Heterogêneo (Stacking)\n",
    "study_stacking = optuna.create_study(direction='maximize')\n",
    "study_stacking.optimize(objective_stacking, n_trials=n_trials, callbacks=[mlflc])\n",
    "\n",
    "# Modelo meta com os melhores hiperparâmetros\n",
    "final_estimator = LogisticRegression(\n",
    "    C=study_stacking.best_params['C'],\n",
    "    penalty=study_stacking.best_params['penalty'],\n",
    "    solver=study_stacking.best_params['solver']\n",
    ")\n",
    "\n",
    "# Modelos base (mantidos os mesmos)\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svm', SVC(probability=True, random_state=42)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "best_stacking = StackingClassifier(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
    "\n",
    "best_models['Comitê Heterogêneo (Stacking)'] = best_stacking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgboost, n_trials=n_trials, callbacks=[mlflc])\n",
    "best_xgb = XGBClassifier(**study_xgb.best_params, use_label_encoder=False, eval_metric='logloss')\n",
    "best_models['XGBoost'] = best_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "study_lgbm = optuna.create_study(direction='maximize')\n",
    "study_lgbm.optimize(objective_lightgbm, n_trials=n_trials, callbacks=[mlflc])\n",
    "best_lgbm = LGBMClassifier(**study_lgbm.best_params)\n",
    "best_models['LightGBM'] = best_lgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação dos Melhores Modelos e Registro no MLflow\n",
    "for model_name, model in best_models.items():\n",
    "    with mlflow.start_run(run_name=f\"{model_name} - Optuna HPO\"):\n",
    "        acc, f1, recall, roc_auc = evaluate_model(model, X_train, y_train, X_val, y_val)\n",
    "        # Registrando os melhores hiperparâmetros\n",
    "        if model_name == 'K-NN':\n",
    "            mlflow.log_params(study_knn.best_params)\n",
    "        elif model_name == 'Árvore de Decisão':\n",
    "            mlflow.log_params(study_dt.best_params)\n",
    "        elif model_name == 'SVM':\n",
    "            mlflow.log_params(study_svm.best_params)\n",
    "        elif model_name == 'Random Forest':\n",
    "            mlflow.log_params(study_rf.best_params)\n",
    "        elif model_name == 'Rede Neural MLP':\n",
    "            mlflow.log_params(study_mlp.best_params)\n",
    "        elif model_name == 'Comitê de Redes Neurais Artificiais':\n",
    "            mlflow.log_params(study_committee_nn.best_params)\n",
    "        elif model_name == 'Comitê Heterogêneo (Stacking)':\n",
    "            mlflow.log_params(study_stacking.best_params)\n",
    "        elif model_name == 'XGBoost':\n",
    "            mlflow.log_params(study_xgb.best_params)\n",
    "        elif model_name == 'LightGBM':\n",
    "            mlflow.log_params(study_lgbm.best_params)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        if roc_auc is not None:\n",
    "            mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        # Salvar o modelo\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        print(f\"{model_name} com Optuna HPO - Acurácia: {acc}, F1-Score: {f1}, Recall: {recall}, ROC AUC: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando o Melhor Modelo\n",
    "# Supondo que o melhor modelo seja o 'XGBoost'\n",
    "best_model_name = 'XGBoost'\n",
    "best_model = best_models[best_model_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o Melhor Modelo no Conjunto Combinado e Avaliando no Conjunto de Teste\n",
    "# Combinando os conjuntos de treinamento e validação\n",
    "X_combined = pd.concat([X_train, X_val])\n",
    "y_combined = pd.concat([y_train, y_val])\n",
    "\n",
    "# Treinando o melhor modelo\n",
    "best_model.fit(X_combined, y_combined)\n",
    "\n",
    "# Avaliando no conjunto de teste\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "acc_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "y_prob_test = best_model.predict_proba(X_test)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
    "roc_auc_test = roc_auc_score(y_test, y_prob_test) if y_prob_test is not None else None\n",
    "\n",
    "print(f\"Desempenho no conjunto de teste - Acurácia: {acc_test}, F1-Score: {f1_test}, Recall: {recall_test}, ROC AUC: {roc_auc_test}\")\n",
    "\n",
    "# Registrando no MLflow\n",
    "with mlflow.start_run(run_name=\"Melhor Modelo - Teste\"):\n",
    "    mlflow.log_param(\"model_type\", best_model_name)\n",
    "    mlflow.log_metric(\"accuracy_test\", acc_test)\n",
    "    mlflow.log_metric(\"f1_score_test\", f1_test)\n",
    "    mlflow.log_metric(\"recall_test\", recall_test)\n",
    "    if roc_auc_test is not None:\n",
    "        mlflow.log_metric(\"roc_auc_test\", roc_auc_test)\n",
    "    mlflow.sklearn.log_model(best_model, \"Melhor_Modelo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizações Adicionais\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Matriz de Confusão\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Matriz de Confusão - Conjunto de Teste\")\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "if roc_auc_test is not None:\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob_test)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc_test:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Linha diagonal\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Curva ROC - Conjunto de Teste')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação dos Modelos\n",
    "results = []\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    acc, f1, recall, roc_auc = evaluate_model(model, X_train, y_train, X_val, y_val)\n",
    "    results.append({\n",
    "        'Modelo': model_name,\n",
    "        'Acurácia': acc,\n",
    "        'F1-Score': f1,\n",
    "        'Recall': recall,\n",
    "        'ROC AUC': roc_auc\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando as métricas\n",
    "results_df_melted = results_df.melt(id_vars='Modelo', value_vars=['Acurácia', 'F1-Score', 'Recall', 'ROC AUC'], var_name='Métrica', value_name='Valor')\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x='Modelo', y='Valor', hue='Métrica', data=results_df_melted)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Comparação das Métricas dos Modelos')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementação da Metodologia de Janez Demsar\n",
    "from scipy.stats import friedmanchisquare\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Supondo que você tenha as acurácias de cada modelo em diferentes folds\n",
    "# Exemplo simplificado\n",
    "model_scores = {\n",
    "    'K-NN': [0.8, 0.82, 0.81, 0.79, 0.8],\n",
    "    'Árvore de Decisão': [0.85, 0.83, 0.84, 0.86, 0.85],\n",
    "    # Adicione os demais modelos\n",
    "}\n",
    "\n",
    "# Convertendo para DataFrame\n",
    "scores_df = pd.DataFrame(model_scores)\n",
    "\n",
    "# Teste de Friedman\n",
    "stat, p = friedmanchisquare(*[scores_df[model] for model in scores_df.columns])\n",
    "print(f'Estatística: {stat}, p-valor: {p}')\n",
    "\n",
    "# Se p-valor < 0.05, há diferença significativa\n",
    "if p < 0.05:\n",
    "    print('Diferença significativa entre os modelos. Realizando teste de Nemenyi.')\n",
    "    nemenyi = sp.posthoc_nemenyi_friedman(scores_df.values)\n",
    "    print(nemenyi)\n",
    "else:\n",
    "    print('Não há diferença significativa entre os modelos.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
